#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„è§†é¢‘åˆ†æè„šæœ¬ï¼Œé¿å…æ‰€æœ‰è¾“å…¥é—®é¢˜
"""
import os
import cv2
import numpy as np
from gaze_analyzer import GazeAnalyzer

def analyze_video_simple(video_path, model_path="gaze_model.json", output_dir="analysis_results"):
    """ç®€åŒ–çš„è§†é¢‘åˆ†æå‡½æ•°"""
    print(f"ğŸ¬ å¼€å§‹åˆ†æ: {os.path.basename(video_path)}")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = GazeAnalyzer()
    analyzer.load_model(model_path)
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return None
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.2f}fps, {total_frames}å¸§")
    
    # åˆå§‹åŒ–åˆ†æå™¨çŠ¶æ€
    analyzer.segments = []
    analyzer.current_state = None
    analyzer.pending_state = None
    analyzer.pending_start_frame = 0
    analyzer.last_gaze_position = None
    analyzer.scene_vote_history = []
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        output_video_path = os.path.join(output_dir, f"{os.path.splitext(os.path.basename(video_path))[0]}_analyzed.mp4")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
    else:
        output_video = None
    
    frame_num = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # æ£€æµ‹è§†çº¿ç‚¹
            gaze_circle, black_mask = analyzer.detect_gaze_circle(frame)
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            pure_black_mask = analyzer.create_pure_black_mask(gray_frame)
            overlay_mask = black_mask if black_mask is not None else pure_black_mask
            
            # è®¡ç®—åœºæ™¯ç‰¹å¾
            scene_features = analyzer.compute_scene_features(frame, overlay_mask)
            scene_guess = scene_features.get('scene_guess', 'virtual')
            scene_guess = analyzer.update_scene_history(scene_guess)
            scene_features['scene_guess'] = scene_guess
            
            # åˆ†æè§†çº¿åŒºåŸŸ
            if gaze_circle:
                gaze_x, gaze_y, radius = gaze_circle
                raw_state = analyzer.analyze_gaze_region(frame, gaze_x, gaze_y, black_mask, scene_features)
                cv2.circle(frame, (gaze_x, gaze_y), radius, (255, 255, 0), 2)
                cv2.circle(frame, (gaze_x, gaze_y), analyzer.detection_radius, (0, 255, 255), 1)
            else:
                raw_state = scene_guess
            
            # æ›´æ–°çŠ¶æ€
            analyzer.update_state(raw_state, frame_num, fps)
            stable_state = analyzer.current_state if analyzer.current_state is not None else raw_state
            
            # ç»˜åˆ¶æŒ‡ç¤ºå™¨
            analyzer.draw_indicator(frame, stable_state)
            
            # ç»˜åˆ¶é®ç½©æŒ‡ç¤ºå™¨
            if black_mask is not None:
                analyzer.draw_mask_indicator(frame, frame.copy(), black_mask, scene_features)
            
            # è¿›åº¦æ˜¾ç¤º
            if frame_num % 100 == 0 and total_frames > 0:
                progress = (frame_num / total_frames) * 100
                print(f"â³ å¤„ç†è¿›åº¦: {progress:.1f}% ({frame_num}/{total_frames})")
            
            # å†™å…¥è¾“å‡ºè§†é¢‘
            if output_video:
                output_video.write(frame)
            
            frame_num += 1
    
    finally:
        cap.release()
        if output_video:
            output_video.release()
    
    # å®Œæˆæœ€åçš„ç‰‡æ®µ
    analyzer.finalize_segments(frame_num, fps)
    
    print(f"âœ… åˆ†æå®Œæˆ! å…±å¤„ç† {frame_num} å¸§")
    
    # ç”ŸæˆæŠ¥å‘Š
    analyzer.generate_report(video_path, output_dir)
    
    return analyzer.segments

def main():
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python simple_analyze.py <è§†é¢‘è·¯å¾„>")
        print("ç¤ºä¾‹: python simple_analyze.py 'çœ¼åŠ¨æ•°æ®/P9_qihang/P9_9.mp4'")
        sys.exit(1)
    
    video_path = sys.argv[1]
    
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        sys.exit(1)
    
    segments = analyze_video_simple(video_path)
    
    if segments:
        print(f"âœ… æ£€æµ‹åˆ° {len(segments)} ä¸ªç‰‡æ®µ")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°æœ‰æ•ˆç‰‡æ®µ")

if __name__ == "__main__":
    main()
