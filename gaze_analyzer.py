#!/usr/bin/env python3
"""
VRçœ¼åŠ¨æ•°æ®è‡ªåŠ¨åˆ†æå·¥å…· / VR Gaze Data Auto Analysis Tool

åŠŸèƒ½è¯´æ˜ï¼š
- è‡ªåŠ¨æ£€æµ‹è§†é¢‘ä¸­çš„ç™½è‰²åœ†å½¢è§†çº¿ç‚¹
- åˆ†æè§†çº¿ç‚¹å‘¨å›´åŒºåŸŸåˆ¤æ–­ç°å®ä¸–ç•Œvsè™šæ‹Ÿä¸–ç•Œ
- ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šå’Œæ—¶é—´æ®µç»Ÿè®¡
- æ”¯æŒå®æ—¶é¢„è§ˆå’Œæ‰¹é‡å¤„ç†

ä½œè€…ï¼šWeihao
ç‰ˆæœ¬ï¼š1.0
æ–‡ä»¶åï¼šgaze_analyzer.py
"""
import cv2
import numpy as np
import os
import pandas as pd
from collections import defaultdict
import argparse
import glob

class GazeAnalyzer:
    def __init__(self):
        # æ£€æµ‹å‚æ•°
        self.black_threshold = 30  # é»‘è‰²é˜ˆå€¼ï¼ˆ0-255ï¼‰
        self.detection_radius = 20  # è§†çº¿ç‚¹å‘¨å›´æ£€æµ‹åŠå¾„
        self.min_duration = 5  # æœ€å°æŒç»­å¸§æ•°ï¼ˆé¿å…å™ªå£°ï¼‰
        
        # æ˜¾ç¤ºå‚æ•°
        self.indicator_size = (100, 80)  # æŒ‡ç¤ºå™¨å¤§å°
        self.indicator_pos = (20, 20)   # æŒ‡ç¤ºå™¨ä½ç½®
        
        # çŠ¶æ€è¿½è¸ª
        self.current_state = None  # 'reality' or 'virtual'
        self.state_start_frame = 0
        self.segments = []  # å­˜å‚¨æ‰€æœ‰ç‰‡æ®µ
        
        # è¿‘å¤„ä¼˜å…ˆæ£€æµ‹
        self.last_gaze_position = None  # ä¸Šä¸€å¸§çš„è§†çº¿ä½ç½®
        self.proximity_radius = 128     # è¿‘å¤„æœç´¢åŠå¾„
        
        # åœ†å½¢è´¨é‡æ§åˆ¶å‚æ•°
        self.min_circle_fill_ratio = 0.55
        self.max_circle_std_ratio = 0.6
        self.max_ring_intensity_gap = 25
        self.min_perimeter_brightness_ratio = 0.7
        self.max_color_std_for_circle = 35.0
        
    def detect_gaze_circle(self, frame):
        """æ£€æµ‹ç™½è‰²åœ†å½¢è§†çº¿ç‚¹"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—æ’é™¤åŒºåŸŸè¾¹ç•Œ - æ’é™¤é¡¶éƒ¨5%å’Œå·¦å³ä¸¤ä¾§10%
        h, w = gray.shape
        top_exclude = int(h * 0.05)      # é¡¶éƒ¨5%
        left_exclude = int(w * 0.23)     # å·¦ä¾§10%
        right_exclude = w - int(w * 0.23) # å³ä¾§10%
        
        # åˆ›å»ºé»‘è‰²åŒºåŸŸmask
        black_mask = self.create_black_region_mask(gray)
        
        # è¿‘å¤„ä¼˜å…ˆæ£€æµ‹ï¼šå¦‚æœæœ‰ä¸Šä¸€å¸§çš„ä½ç½®ï¼Œä¼˜å…ˆåœ¨é™„è¿‘æœç´¢
        if self.last_gaze_position is not None:
            proximity_circle = self.detect_with_proximity_priority(frame, gray, left_exclude, right_exclude, top_exclude)
            if proximity_circle:
                self.last_gaze_position = (proximity_circle[0], proximity_circle[1])
                return proximity_circle, black_mask
        
        # å…ˆå°è¯•æ ‡å‡†å‚æ•°æ£€æµ‹
        circles = cv2.HoughCircles(
            gray,
            cv2.HOUGH_GRADIENT,
            dp=1,
            minDist=30,  # å‡å°æœ€å°è·ç¦»é¿å…æ–¹å‘ç›˜åœ†åœˆå¹²æ‰°
            param1=60,   # æé«˜è¾¹ç¼˜æ£€æµ‹é˜ˆå€¼
            param2=35,   # æé«˜ç´¯åŠ å™¨é˜ˆå€¼å‡å°‘è¯¯è¯†åˆ«
            minRadius=3, # å‡å°50%: 5->3
            maxRadius=12 # å‡å°50%: 25->12
        )
        
        # ä¼˜å…ˆåœ¨é»‘è‰²åŒºåŸŸå†…ç”¨é«˜æ•æ„Ÿåº¦æ£€æµ‹
        black_region_circle = self.detect_in_black_region(frame, gray, black_mask, left_exclude, right_exclude, top_exclude)
        if black_region_circle:
            self.last_gaze_position = (black_region_circle[0], black_region_circle[1])
            return black_region_circle, black_mask
        
        # å¦‚æœé»‘è‰²åŒºåŸŸæ²¡æ£€æµ‹åˆ°ï¼Œä½¿ç”¨æ ‡å‡†å‚æ•°åœ¨å…¨å›¾æ£€æµ‹
        if circles is None:
            avg_brightness = np.mean(gray)
            if avg_brightness < 80:  # åˆ¤æ–­ä¸ºæš—èƒŒæ™¯
                circles = cv2.HoughCircles(
                    gray,
                    cv2.HOUGH_GRADIENT,
                    dp=1,
                    minDist=25,  # è¿›ä¸€æ­¥å‡å°è·ç¦»
                    param1=40,   # é™ä½è¾¹ç¼˜æ£€æµ‹é˜ˆå€¼ï¼Œå¢åŠ æ•æ„Ÿåº¦
                    param2=20,   # å¤§å¹…é™ä½ç´¯åŠ å™¨é˜ˆå€¼
                    minRadius=3,
                    maxRadius=12
                )
        
        if circles is not None:
            circles = np.round(circles[0, :]).astype("int")
            frame_avg_brightness = float(np.mean(gray))
            
            # æ‰¾åˆ°æœ€äº®çš„åœ†ï¼ˆå¯èƒ½æ˜¯è§†çº¿ç‚¹ï¼‰
            best_circle = None
            max_brightness = 0
            
            for (x, y, r) in circles:
                # æ£€æŸ¥æ˜¯å¦åœ¨æœ‰æ•ˆæ£€æµ‹åŒºåŸŸå†…ï¼ˆæ’é™¤é¡¶éƒ¨5%å’Œå·¦å³ä¸¤ä¾§10%ï¼‰
                if (left_exclude <= x <= right_exclude and 
                    y >= top_exclude and 
                    0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–¹å‘ç›˜æŒ‰é’®ï¼ˆç™½è‰²è¾¹ç•Œ+é»‘è‰²å†…éƒ¨ï¼‰
                    if self.is_steering_wheel_button(gray, x, y, r):
                        continue  # è·³è¿‡æ–¹å‘ç›˜æŒ‰é’®
                    
                    metrics = self.evaluate_circle_candidate(frame, gray, x, y, r)
                    if metrics is None:
                        continue

                    brightness = metrics["mean"]
                    contrast = metrics["contrast"]

                    if frame_avg_brightness < 80:
                        score = brightness * 0.4 + contrast * 0.6
                        if brightness > 150 and contrast > 50:
                            score += 50
                    else:
                        score = brightness * 0.7 + contrast * 0.3

                    if score > max_brightness:
                        max_brightness = score
                        best_circle = (x, y, r)
            
            # æ›´æ–°æœ€åæ£€æµ‹åˆ°çš„ä½ç½®
            if best_circle is not None:
                self.last_gaze_position = (best_circle[0], best_circle[1])
            
            return best_circle, black_mask
        
        return None, black_mask
    
    def is_steering_wheel_button(self, gray, x, y, r):
        """æ£€æµ‹æ˜¯å¦æ˜¯æ–¹å‘ç›˜æŒ‰é’®ï¼ˆç™½è‰²è¾¹ç•Œ+é»‘è‰²å†…éƒ¨ï¼‰"""
        # æ£€æŸ¥åœ†å¿ƒåŒºåŸŸ
        center_r = max(1, int(r * 0.6))  # å†…éƒ¨åŒºåŸŸåŠå¾„
        center_roi = gray[max(0, y-center_r):min(gray.shape[0], y+center_r),
                         max(0, x-center_r):min(gray.shape[1], x+center_r)]
        
        # æ£€æŸ¥è¾¹ç•ŒåŒºåŸŸ
        edge_r = r
        edge_roi = gray[max(0, y-edge_r):min(gray.shape[0], y+edge_r),
                       max(0, x-edge_r):min(gray.shape[1], x+edge_r)]
        
        if center_roi.size == 0 or edge_roi.size == 0:
            return False
        
        center_brightness = np.mean(center_roi)
        edge_brightness = np.mean(edge_roi)
        
        # æ–¹å‘ç›˜ç‰¹å¾ï¼šè¾¹ç•Œäº®ï¼ˆç™½è‰²ï¼‰ï¼Œä¸­å¿ƒæš—ï¼ˆé»‘è‰²æŒ‰é’®ï¼‰
        # çœŸå®è§†çº¿ç‚¹ç‰¹å¾ï¼šæ•´ä½“éƒ½æ˜¯ç™½è‰²ï¼Œä¸­å¿ƒä¹Ÿå¾ˆäº®
        is_steering_wheel = (
            edge_brightness > 120 and          # è¾¹ç•Œè¾ƒäº®ï¼ˆç™½è‰²è¾¹ç•Œï¼‰
            center_brightness < 80 and         # ä¸­å¿ƒè¾ƒæš—ï¼ˆé»‘è‰²æŒ‰é’®ï¼‰
            (edge_brightness - center_brightness) > 60  # è¾¹ç•Œä¸ä¸­å¿ƒå¯¹æ¯”åº¦é«˜
        )
        
        return is_steering_wheel
    
    def evaluate_circle_candidate(self, frame, gray, x, y, r):
        """Compute metrics for a detected circle and filter out open rings or noisy blobs."""
        h, w = gray.shape
        radius = int(max(2, round(r)))
        if radius <= 1:
            return None
        pad = max(radius + 2, int(radius * 1.5))
        x1 = max(0, x - pad)
        y1 = max(0, y - pad)
        x2 = min(w, x + pad + 1)
        y2 = min(h, y + pad + 1)
        roi_gray = gray[y1:y2, x1:x2]
        if roi_gray.size == 0:
            return None
        center = (x - x1, y - y1)
        mask = np.zeros_like(roi_gray, dtype=np.uint8)
        cv2.circle(mask, center, radius, 255, -1)
        circle_pixels = roi_gray[mask == 255]
        min_pixels = max(10, int(np.pi * radius * radius * 0.45))
        if circle_pixels.size < min_pixels:
            return None
        circle_pixels = circle_pixels.astype(np.float32)
        mean_intensity = float(np.mean(circle_pixels))
        if mean_intensity < 90:
            return None
        std_intensity = float(np.std(circle_pixels))
        std_ratio = std_intensity / (mean_intensity + 1e-6)
        inner_r = max(1, int(radius * 0.55))
        inner_mask = np.zeros_like(mask, dtype=np.uint8)
        cv2.circle(inner_mask, center, inner_r, 255, -1)
        inner_pixels = roi_gray[inner_mask == 255]
        inner_mean = float(np.mean(inner_pixels)) if inner_pixels.size > 0 else mean_intensity
        ring_mask = np.zeros_like(mask, dtype=np.uint8)
        cv2.circle(ring_mask, center, radius, 255, -1)
        ring_inner_r = max(inner_r, int(radius * 0.75))
        cv2.circle(ring_mask, center, ring_inner_r, 0, -1)
        ring_pixels = roi_gray[ring_mask == 255]
        ring_mean = float(np.mean(ring_pixels)) if ring_pixels.size > 0 else mean_intensity
        _, binary = cv2.threshold(roi_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        fill_pixels = int(np.sum((binary == 255) & (mask == 255)))
        fill_ratio = fill_pixels / circle_pixels.size
        perimeter_mask = np.zeros_like(mask, dtype=np.uint8)
        cv2.circle(perimeter_mask, center, radius, 255, 1)
        perimeter_pixels = roi_gray[perimeter_mask == 255].astype(np.float32)
        perimeter_threshold = mean_intensity - 12.0
        if perimeter_pixels.size > 0:
            perimeter_ratio = float(np.mean(perimeter_pixels > perimeter_threshold))
        else:
            perimeter_ratio = 1.0
        surround_x1 = max(0, x - radius * 2)
        surround_y1 = max(0, y - radius * 2)
        surround_x2 = min(w, x + radius * 2 + 1)
        surround_y2 = min(h, y + radius * 2 + 1)
        surrounding_roi = gray[surround_y1:surround_y2, surround_x1:surround_x2]
        if surrounding_roi.size > 0:
            contrast = mean_intensity - float(np.mean(surrounding_roi))
        else:
            contrast = 0.0
        color_std = None
        if frame is not None:
            roi_color = frame[y1:y2, x1:x2]
            if roi_color.size > 0:
                circle_colors = roi_color[mask == 255].astype(np.float32)
                if circle_colors.size > 0:
                    color_std = float(np.mean(np.std(circle_colors, axis=0)))
        ring_gap = ring_mean - inner_mean
        if fill_ratio < self.min_circle_fill_ratio:
            return None
        if perimeter_ratio < self.min_perimeter_brightness_ratio:
            return None
        if ring_gap > self.max_ring_intensity_gap and inner_mean < 175:
            return None
        if std_ratio > self.max_circle_std_ratio and fill_ratio < 0.85:
            return None
        if color_std is not None and color_std > self.max_color_std_for_circle and fill_ratio < 0.8:
            return None
        return {
            "mean": mean_intensity,
            "contrast": contrast,
            "fill_ratio": fill_ratio,
            "std_ratio": std_ratio,
            "ring_diff": ring_gap,
            "perimeter_ratio": perimeter_ratio,
            "color_std": color_std,
            "inner_mean": inner_mean,
            "ring_mean": ring_mean,
        }

    def detect_with_proximity_priority(self, frame, gray, left_exclude, right_exclude, top_exclude):
        """è¿‘å¤„ä¼˜å…ˆæ£€æµ‹ï¼šåœ¨ä¸Šä¸€å¸§ä½ç½®å‘¨å›´é€æ­¥æ‰©å¤§æœç´¢èŒƒå›´"""
        if self.last_gaze_position is None:
            return None

        last_x, last_y = self.last_gaze_position
        h, w = gray.shape

        for search_radius in [128, 256, 384]:
            search_x1 = max(left_exclude, last_x - search_radius)
            search_y1 = max(top_exclude, last_y - search_radius)
            search_x2 = min(right_exclude, last_x + search_radius)
            search_y2 = min(h, last_y + search_radius)

            if search_x2 - search_x1 < 50 or search_y2 - search_y1 < 50:
                continue

            search_roi = gray[search_y1:search_y2, search_x1:search_x2]

            circles = cv2.HoughCircles(
                search_roi,
                cv2.HOUGH_GRADIENT,
                dp=1,
                minDist=20,
                param1=35,
                param2=25,
                minRadius=3,
                maxRadius=12
            )

            if circles is not None:
                circles = np.round(circles[0, :]).astype("int")

                best_circle = None
                min_distance = float('inf')

                for (rel_x, rel_y, r) in circles:
                    abs_x = rel_x + search_x1
                    abs_y = rel_y + search_y1

                    if not (left_exclude <= abs_x <= right_exclude and abs_y >= top_exclude):
                        continue

                    if self.is_steering_wheel_button(gray, abs_x, abs_y, r):
                        continue

                    metrics = self.evaluate_circle_candidate(frame, gray, abs_x, abs_y, r)
                    if metrics is None:
                        continue

                    distance = ((abs_x - last_x) ** 2 + (abs_y - last_y) ** 2) ** 0.5

                    if metrics["mean"] > 100 and distance < min_distance:
                        min_distance = distance
                        best_circle = (abs_x, abs_y, r)

                if best_circle is not None:
                    return best_circle

        return None

    def create_black_region_mask(self, gray):
        """åˆ›å»ºé»‘è‰²åŒºåŸŸçš„mask"""
        # ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼æ£€æµ‹é»‘è‰²åŒºåŸŸ
        binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                      cv2.THRESH_BINARY_INV, 15, 10)
        
        # å½¢æ€å­¦å¤„ç†ï¼Œè¿æ¥é»‘è‰²åŒºåŸŸ
        kernel = np.ones((5,5), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # æ‰¾åˆ°æœ€å¤§çš„é»‘è‰²åŒºåŸŸ
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            # é€‰æ‹©é¢ç§¯æœ€å¤§çš„è½®å»“
            largest_contour = max(contours, key=cv2.contourArea)
            mask = np.zeros_like(gray)
            cv2.fillPoly(mask, [largest_contour], 255)
            return mask
        
        return np.zeros_like(gray)
    
    def detect_in_black_region(self, frame, gray, black_mask, left_exclude, right_exclude, top_exclude):
        """åœ¨é»‘è‰²åŒºåŸŸå†…ç”¨é«˜æ•æ„Ÿåº¦æ£€æµ‹ç™½ç‚¹"""
        if black_mask is None:
            return None

        circles = cv2.HoughCircles(
            gray,
            cv2.HOUGH_GRADIENT,
            dp=1,
            minDist=15,
            param1=25,
            param2=15,
            minRadius=3,
            maxRadius=12
        )

        if circles is None:
            return None

        circles = np.round(circles[0, :]).astype("int")

        best_circle = None
        max_score = 0.0

        for (x, y, r) in circles:
            if not (left_exclude <= x <= right_exclude and y >= top_exclude):
                continue

            if black_mask[y, x] == 0:
                continue

            if self.is_steering_wheel_button(gray, x, y, r):
                continue

            metrics = self.evaluate_circle_candidate(frame, gray, x, y, r)
            if metrics is None:
                continue

            brightness = metrics["mean"]
            contrast = metrics["contrast"]

            if brightness < 120:
                continue

            score = brightness + contrast * 2.0

            if score > max_score:
                max_score = score
                best_circle = (x, y, r)

        return best_circle

    def analyze_gaze_region(self, frame, gaze_x, gaze_y):
        """åˆ†æè§†çº¿ç‚¹å‘¨å›´åŒºåŸŸåˆ¤æ–­æ˜¯ç°å®è¿˜æ˜¯è™šæ‹Ÿ"""
        h, w = frame.shape[:2]
        
        # ç¡®ä¿æ£€æµ‹åŒºåŸŸåœ¨å›¾åƒèŒƒå›´å†…
        x1 = max(0, gaze_x - self.detection_radius)
        y1 = max(0, gaze_y - self.detection_radius)
        x2 = min(w, gaze_x + self.detection_radius)
        y2 = min(h, gaze_y + self.detection_radius)
        
        # æå–æ£€æµ‹åŒºåŸŸ
        roi = frame[y1:y2, x1:x2]
        
        if roi.size == 0:
            return 'unknown'
        
        # è½¬æ¢ä¸ºç°åº¦å¹¶è®¡ç®—å¹³å‡äº®åº¦
        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        avg_brightness = np.mean(gray_roi)
        
        # è®¡ç®—é»‘è‰²åƒç´ æ¯”ä¾‹
        black_pixels = np.sum(gray_roi < self.black_threshold)
        total_pixels = gray_roi.size
        black_ratio = black_pixels / total_pixels
        
        # åˆ¤æ–­é€»è¾‘ï¼šå¦‚æœé»‘è‰²åƒç´ æ¯”ä¾‹è¶…è¿‡50%æˆ–å¹³å‡äº®åº¦å¾ˆä½ï¼Œè®¤ä¸ºæ˜¯ç°å®ä¸–ç•Œ
        if black_ratio > 0.5 or avg_brightness < self.black_threshold:
            return 'reality'
        else:
            return 'virtual'
    
    def draw_indicator(self, frame, state):
        """åœ¨å·¦ä¸Šè§’ç»˜åˆ¶çŠ¶æ€æŒ‡ç¤ºå™¨"""
        x, y = self.indicator_pos
        w, h = self.indicator_size
        
        # é€‰æ‹©é¢œè‰²
        if state == 'reality':
            color = (0, 255, 0)  # ç»¿è‰²
            text = 'REALITY'
        elif state == 'virtual':
            color = (0, 0, 255)  # çº¢è‰²
            text = 'VIRTUAL'
        else:
            color = (128, 128, 128)  # ç°è‰²
            text = 'UNKNOWN'
        
        # ç»˜åˆ¶çŸ©å½¢æŒ‡ç¤ºå™¨
        cv2.rectangle(frame, (x, y), (x + w, y + h), color, -1)
        
        # æ·»åŠ æ–‡å­—
        font = cv2.FONT_HERSHEY_SIMPLEX
        text_size = cv2.getTextSize(text, font, 0.6, 2)[0]
        text_x = x + (w - text_size[0]) // 2
        text_y = y + (h + text_size[1]) // 2
        cv2.putText(frame, text, (text_x, text_y), font, 0.6, (255, 255, 255), 2)
    
    def draw_mask_indicator(self, frame, black_mask):
        """åœ¨å·¦ä¸‹è§’æ˜¾ç¤ºé»‘è‰²åŒºåŸŸmaskçš„ç¼©ç•¥å›¾"""
        h, w = frame.shape[:2]
        
        # ç¼©ç•¥å›¾å¤§å°
        thumb_w, thumb_h = 120, 80
        thumb_x = 20
        thumb_y = h - thumb_h - 20
        
        # ç¼©æ”¾maskåˆ°ç¼©ç•¥å›¾å¤§å°
        mask_resized = cv2.resize(black_mask, (thumb_w, thumb_h))
        
        # åˆ›å»ºå½©è‰²ç‰ˆæœ¬çš„mask (ç™½è‰²åŒºåŸŸæ˜¾ç¤ºä¸ºç»¿è‰²)
        # å°†maskè½¬æ¢ä¸º3é€šé“ï¼Œç™½è‰²åŒºåŸŸæ˜¾ç¤ºä¸ºç»¿è‰²
        mask_colored = np.zeros((thumb_h, thumb_w, 3), dtype=np.uint8)
        mask_colored[:, :, 1] = mask_resized  # ç»¿è‰²é€šé“
        
        # åœ¨åŸå›¾ä¸Šå åŠ ç¼©ç•¥å›¾
        frame[thumb_y:thumb_y+thumb_h, thumb_x:thumb_x+thumb_w] = mask_colored
        
        # ç»˜åˆ¶è¾¹æ¡†
        cv2.rectangle(frame, (thumb_x, thumb_y), (thumb_x+thumb_w, thumb_y+thumb_h), (255, 255, 255), 2)
        
        # æ·»åŠ æ ‡ç­¾
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(frame, 'Black Mask', (thumb_x, thumb_y-5), font, 0.4, (255, 255, 255), 1)
    
    def update_state(self, new_state, frame_num, fps):
        """æ›´æ–°çŠ¶æ€å¹¶è®°å½•ç‰‡æ®µ"""
        if new_state != self.current_state:
            # çŠ¶æ€æ”¹å˜ï¼Œè®°å½•ä¸Šä¸€ä¸ªç‰‡æ®µ
            if self.current_state is not None and frame_num - self.state_start_frame >= self.min_duration:
                duration_frames = frame_num - self.state_start_frame
                duration_seconds = duration_frames / fps
                
                self.segments.append({
                    'state': self.current_state,
                    'start_frame': self.state_start_frame,
                    'end_frame': frame_num - 1,
                    'duration_frames': duration_frames,
                    'duration_seconds': duration_seconds,
                    'start_time': self.state_start_frame / fps,
                    'end_time': (frame_num - 1) / fps
                })
            
            # å¼€å§‹æ–°çŠ¶æ€
            self.current_state = new_state
            self.state_start_frame = frame_num
    
    def finalize_segments(self, total_frames, fps):
        """å®Œæˆæœ€åä¸€ä¸ªç‰‡æ®µçš„è®°å½•"""
        if self.current_state is not None and total_frames - self.state_start_frame >= self.min_duration:
            duration_frames = total_frames - self.state_start_frame
            duration_seconds = duration_frames / fps
            
            self.segments.append({
                'state': self.current_state,
                'start_frame': self.state_start_frame,
                'end_frame': total_frames - 1,
                'duration_frames': duration_frames,
                'duration_seconds': duration_seconds,
                'start_time': self.state_start_frame / fps,
                'end_time': (total_frames - 1) / fps
            })
    
    def analyze_video(self, video_path, output_dir=None, show_preview=True):
        """åˆ†æè§†é¢‘æ–‡ä»¶"""
        print(f"ğŸ¬ å¼€å§‹åˆ†æè§†é¢‘: {os.path.basename(video_path)}")
        
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return None
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.2f}fps, {total_frames}å¸§")
        
        # é‡ç½®çŠ¶æ€
        self.segments = []
        self.current_state = None
        
        frame_num = 0
        
        # å¦‚æœéœ€è¦ä¿å­˜å¤„ç†åçš„è§†é¢‘
        output_video = None
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
            output_video_path = os.path.join(output_dir, f"{os.path.splitext(os.path.basename(video_path))[0]}_analyzed.mp4")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # æ£€æµ‹è§†çº¿ç‚¹
                detection_result = self.detect_gaze_circle(frame)
                
                current_state = 'unknown'
                gaze_circle = None
                black_mask = None
                
                if detection_result and len(detection_result) == 2:
                    gaze_circle, black_mask = detection_result
                
                if gaze_circle:
                    gaze_x, gaze_y, radius = gaze_circle
                    
                    # åˆ†æè§†çº¿åŒºåŸŸ
                    current_state = self.analyze_gaze_region(frame, gaze_x, gaze_y)
                    
                    # åœ¨è§†çº¿ç‚¹ç»˜åˆ¶åœ†åœˆï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    cv2.circle(frame, (gaze_x, gaze_y), radius, (255, 255, 0), 2)
                    cv2.circle(frame, (gaze_x, gaze_y), self.detection_radius, (0, 255, 255), 1)
                else:
                    # åå‘é€»è¾‘ï¼šå¦‚æœé»‘è‰²åŒºåŸŸå†…æ²¡æœ‰æ£€æµ‹åˆ°ç™½åœˆï¼Œåˆ¤æ–­ä¸ºç°å®ä¸–ç•Œ
                    if black_mask is not None and np.sum(black_mask) > 1000:  # ç¡®ä¿æœ‰è¶³å¤Ÿå¤§çš„é»‘è‰²åŒºåŸŸ
                        current_state = 'reality'
                
                # æ›´æ–°çŠ¶æ€
                self.update_state(current_state, frame_num, fps)
                
                # ç»˜åˆ¶çŠ¶æ€æŒ‡ç¤ºå™¨
                self.draw_indicator(frame, current_state)
                
                # åœ¨å·¦ä¸‹è§’æ˜¾ç¤ºé»‘è‰²åŒºåŸŸmask
                if black_mask is not None:
                    self.draw_mask_indicator(frame, black_mask)
                
                # æ˜¾ç¤ºè¿›åº¦
                if frame_num % 100 == 0:
                    progress = (frame_num / total_frames) * 100
                    print(f"â³ å¤„ç†è¿›åº¦: {progress:.1f}% ({frame_num}/{total_frames})")
                
                # ä¿å­˜å¤„ç†åçš„å¸§
                if output_video:
                    output_video.write(frame)
                
                # å®æ—¶é¢„è§ˆ
                if show_preview:
                    # ç¼©æ”¾æ˜¾ç¤ºï¼ˆå¦‚æœè§†é¢‘å¤ªå¤§ï¼‰
                    display_frame = frame
                    if width > 1280:
                        scale = 1280 / width
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        display_frame = cv2.resize(frame, (new_width, new_height))
                    
                    cv2.imshow('Gaze Analysis', display_frame)
                    
                    # æŒ‰ESCé€€å‡ºé¢„è§ˆ
                    if cv2.waitKey(1) & 0xFF == 27:
                        print("â¹ï¸  ç”¨æˆ·ä¸­æ–­é¢„è§ˆ")
                        break
                
                frame_num += 1
            
        finally:
            cap.release()
            if output_video:
                output_video.release()
            if show_preview:
                cv2.destroyAllWindows()
        
        # å®Œæˆæœ€åä¸€ä¸ªç‰‡æ®µ
        self.finalize_segments(frame_num, fps)
        
        print(f"âœ… åˆ†æå®Œæˆ! å…±å¤„ç† {frame_num} å¸§")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_report(video_path, output_dir)
        
        return self.segments
    
    def generate_report(self, video_path, output_dir):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not self.segments:
            print("âš ï¸  æ²¡æœ‰æ£€æµ‹åˆ°æœ‰æ•ˆç‰‡æ®µ")
            return
        
        # ç»Ÿè®¡æ•°æ®
        reality_segments = [s for s in self.segments if s['state'] == 'reality']
        virtual_segments = [s for s in self.segments if s['state'] == 'virtual']
        
        reality_duration = sum(s['duration_seconds'] for s in reality_segments)
        virtual_duration = sum(s['duration_seconds'] for s in virtual_segments)
        total_duration = reality_duration + virtual_duration
        
        print(f"\nğŸ“Š åˆ†ææŠ¥å‘Š:")
        print(f"=" * 50)
        print(f"ç°å®ä¸–ç•Œç‰‡æ®µ: {len(reality_segments)} ä¸ª, æ€»æ—¶é•¿: {reality_duration:.2f}ç§’")
        print(f"è™šæ‹Ÿä¸–ç•Œç‰‡æ®µ: {len(virtual_segments)} ä¸ª, æ€»æ—¶é•¿: {virtual_duration:.2f}ç§’")
        
        if total_duration > 0:
            print(f"ç°å®ä¸–ç•Œå æ¯”: {(reality_duration/total_duration*100):.1f}%")
            print(f"è™šæ‹Ÿä¸–ç•Œå æ¯”: {(virtual_duration/total_duration*100):.1f}%")
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        if output_dir:
            # åˆ›å»ºDataFrame
            df_data = []
            for i, segment in enumerate(self.segments, 1):
                df_data.append({
                    'åºå·': i,
                    'çŠ¶æ€': 'ç°å®ä¸–ç•Œ' if segment['state'] == 'reality' else 'è™šæ‹Ÿä¸–ç•Œ',
                    'å¼€å§‹å¸§': segment['start_frame'],
                    'ç»“æŸå¸§': segment['end_frame'],
                    'æŒç»­å¸§æ•°': segment['duration_frames'],
                    'å¼€å§‹æ—¶é—´(ç§’)': round(segment['start_time'], 2),
                    'ç»“æŸæ—¶é—´(ç§’)': round(segment['end_time'], 2),
                    'æŒç»­æ—¶é—´(ç§’)': round(segment['duration_seconds'], 2)
                })
            
            df = pd.DataFrame(df_data)
            
            # ä¿å­˜CSVæ–‡ä»¶
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            csv_path = os.path.join(output_dir, f"{base_name}_analysis.csv")
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            
            print(f"ğŸ“„ è¯¦ç»†æ•°æ®å·²ä¿å­˜: {csv_path}")

def get_video_files(directory):
    """è·å–ç›®å½•ä¸‹çš„è§†é¢‘æ–‡ä»¶"""
    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.flv']
    video_files = []
    
    for ext in video_extensions:
        video_files.extend(glob.glob(os.path.join(directory, '**', ext), recursive=True))
    
    return sorted(video_files)

def main():
    parser = argparse.ArgumentParser(description="VRçœ¼åŠ¨æ•°æ®è‡ªåŠ¨åˆ†æå·¥å…·")
    parser.add_argument("--input", "-i", default="çœ¼åŠ¨æ•°æ®", help="è¾“å…¥ç›®å½•ï¼ˆé»˜è®¤ï¼šçœ¼åŠ¨æ•°æ®ï¼‰")
    parser.add_argument("--output", "-o", default="analysis_results", help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šanalysis_resultsï¼‰")
    parser.add_argument("--no-preview", action="store_true", help="ä¸æ˜¾ç¤ºå®æ—¶é¢„è§ˆ")
    parser.add_argument("--black-threshold", type=int, default=30, help="é»‘è‰²æ£€æµ‹é˜ˆå€¼ï¼ˆé»˜è®¤ï¼š30ï¼‰")
    parser.add_argument("--radius", type=int, default=20, help="æ£€æµ‹åŠå¾„ï¼ˆé»˜è®¤ï¼š20ï¼‰")
    
    args = parser.parse_args()
    
    print("ğŸ¯ VRçœ¼åŠ¨æ•°æ®è‡ªåŠ¨åˆ†æå·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input}")
        return
    
    # è·å–è§†é¢‘æ–‡ä»¶
    video_files = get_video_files(args.input)
    
    if not video_files:
        print(f"âŒ åœ¨ {args.input} ä¸­æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = GazeAnalyzer()
    analyzer.black_threshold = args.black_threshold
    analyzer.detection_radius = args.radius
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨å¹¶è®©ç”¨æˆ·é€‰æ‹©
    print("\nè§†é¢‘æ–‡ä»¶åˆ—è¡¨:")
    for i, video_file in enumerate(video_files, 1):
        rel_path = os.path.relpath(video_file, args.input)
        print(f"{i:2d}. {rel_path}")
    
    try:
        choice = input(f"\nè¯·é€‰æ‹©è¦åˆ†æçš„è§†é¢‘ (1-{len(video_files)}, æˆ– 'all' åˆ†ææ‰€æœ‰): ").strip()
        
        if choice.lower() == 'all':
            selected_files = video_files
        else:
            choice_num = int(choice)
            if 1 <= choice_num <= len(video_files):
                selected_files = [video_files[choice_num - 1]]
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                return
        
        # åˆ†æé€‰å®šçš„è§†é¢‘
        for video_file in selected_files:
            print(f"\nğŸš€ å¼€å§‹åˆ†æ: {os.path.basename(video_file)}")
            
            segments = analyzer.analyze_video(
                video_file, 
                args.output, 
                show_preview=not args.no_preview
            )
            
            if segments:
                print(f"âœ… åˆ†æå®Œæˆï¼Œå…±æ£€æµ‹åˆ° {len(segments)} ä¸ªç‰‡æ®µ")
            else:
                print("âŒ åˆ†æå¤±è´¥")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
    except ValueError:
        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
